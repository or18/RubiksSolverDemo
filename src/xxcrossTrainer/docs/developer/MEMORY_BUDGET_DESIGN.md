# Memory Budget Design: Measured-Based Allocation System

**Version**: 1.0  
**Date**: 2026-01-01  
**Status**: Design Specification (Implementation Pending)

> **Navigation**: [← Back to Developer Docs](../README.md) | [Implementation Details](SOLVER_IMPLEMENTATION.md) | [Memory Monitoring](MEMORY_MONITORING.md)

---

## Executive Summary

This document specifies a **measured-based memory allocation system** that replaces theoretical calculations with empirical RSS measurements. The new design eliminates complex threshold logic, provides explicit bucket allocation models, and includes developer research modes for exploring new trainer configurations.

**Key Changes**:
1. **7 Fixed Bucket Models** (measured RSS data) instead of dynamic candidate selection
2. **Simple Switch-Case Selection** instead of loop-based optimization
3. **Developer Research Modes** for full BFS validation and memory profiling
4. **Measured Peak RSS + Minimal Margin** instead of theoretical prediction + safety margins
5. **Memory Spike Elimination** through implementation review (not detection)

---

## 1. Design Principles

### 1.1 Measured Over Theoretical

**Old Approach** (Deprecated):
```cpp
// Theoretical calculation with safety margin
size_t theoretical_memory = nodes * 24 + buckets * 4;
size_t predicted_rss = theoretical_memory * memory_factor;
if (predicted_rss <= available_memory * 0.98) { ... }  // 2% safety margin
```

**New Approach**:
```cpp
// Direct measurement-based lookup
size_t measured_peak_rss = get_measured_rss(memory_limit_mb);
size_t cpp_internal_margin = measured_peak_rss * 0.02;  // 2% for C++ internals
size_t required_budget = measured_peak_rss + cpp_internal_margin;
// WASM margin added by caller (JS side), not in C++
```

**Rationale**:
- **Simplicity**: No theoretical model maintenance
- **Accuracy**: Real measurements from actual runs
- **Reliability**: Memory spikes already included in measured peak RSS
- **Maintainability**: Update table when hardware/compiler changes

### 1.2 Explicit Over Implicit

**Old**: 11 candidates evaluated dynamically → user unclear what was selected  
**New**: 7 named models → user knows exactly what they're getting

**Models**:
```
1. ULTRA_HIGH:  32M / 64M / 64M  (~1900 MB measured)
2. HIGH:        16M / 32M / 32M  (~1000 MB measured)
3. STANDARD:    8M  / 16M / 16M  (~550 MB measured)
4. MEDIUM:      8M  / 8M  / 8M   (~450 MB measured)
5. BALANCED:    4M  / 8M  / 8M   (~300 MB measured)
6. LOW:         4M  / 4M  / 4M   (~200 MB measured)
7. MINIMAL:     2M  / 4M  / 4M   (~150 MB measured)
```

### 1.3 Developer-Friendly Research

**Problem**: Developing new trainers requires knowing optimal BFS depth and bucket sizes, but this data doesn't exist yet.

**Solution**: Research modes that bypass memory limits and local expansion:
- **Full BFS Mode**: Expand to specified depth without local expansion
- **Memory Profiling Mode**: Measure RSS at each depth without limit enforcement
- **Result**: Developers get empirical data to design optimal configurations

---

## 2. Bucket Allocation Models

### 2.1 Dual Model System: WASM vs Native

**Design Philosophy**: 
- **WASM**: Pre-measured models only (safety-critical)
- **Native**: Flexible custom buckets allowed (developer responsibility)

#### 2.1.1 WASM Pre-Measured Models (7 Variants from Full Computation)

**For WASM environments, use ONLY pre-measured configurations** with guaranteed RSS measurements.

**WASM Model Selection**:
- **User specifies**: Total memory budget (e.g., 300 MB)
- **JavaScript subtracts**: WASM margin (25% reserved → 75% to C++)
- **C++ receives**: 300 * 0.75 = 225 MB
- **C++ selects**: Nearest pre-measured model ≤ 225 MB (e.g., LOW: 190 MB)
- **Result**: Safe, predictable memory usage within 300 MB total budget

**Pre-Measured WASM Models** (7 variants, same as native except ULTRA_HIGH):

| Model ID | depth=7 | depth=8 | depth=9 | Measured Peak RSS | Use Case |
|----------|---------|---------|---------|-------------------|----------|
| **MINIMAL** | 2M | 4M | 4M | 145 MB | Mobile browsers |
| **LOW** | 4M | 4M | 4M | 190 MB | Standard mobile |
| **BALANCED** | 4M | 8M | 8M | 290 MB | **Default WASM** |
| **MEDIUM** | 8M | 8M | 8M | 440 MB | Desktop browsers |
| **STANDARD** | 8M | 16M | 16M | 540 MB | High-performance desktop |
| **HIGH** | 16M | 32M | 32M | 980 MB | Desktop maximum |
| **ULTRA_HIGH** | 32M | 32M | 32M | 1100 MB | **WASM safe limit** |

**Note**: Model gaps are wide (especially above 1GB). **Developers should measure and add intermediate models** (e.g., 300MB, 600MB, 750MB) to improve granularity.

**WASM Safety Rules**:
1. **No custom buckets** in production WASM (developer mode only)
2. **No models >1200 MB** (hard limit: 2GB - 800MB safety)
3. **Automatic fallback** if user budget too low
4. **JavaScript handles WASM margin** (C++ uses raw measured values)

**Example (JavaScript caller)**:
```javascript
// User specifies total budget
const userBudgetMB = 300;

// JS subtracts 25% WASM margin (reserves 25% for browser overhead)
const WASM_MARGIN_RATIO = 0.75;  // 75% to C++, 25% reserved
const cppBudgetMB = Math.floor(userBudgetMB * WASM_MARGIN_RATIO);  // 225 MB

// Allocate WASM memory with full user budget
const memory = new WebAssembly.Memory({
    initial: Math.ceil(userBudgetMB / 64) * 1024,  // Pages (300 MB)
});

// C++ receives budget after margin subtracted
const solver = new Module.xxcross_search(
    true,         // adj
    6,            // BFS_DEPTH
    cppBudgetMB,  // 225 MB (C++ selects LOW: 190 MB)
    false         // verbose
);
// C++ auto-selects LOW (190 MB measured ≤ 225 MB budget)
// Actual peak: ~190 MB + 2% margin = 194 MB
// Safe margin: 300 - 194 = 106 MB (35% headroom for WASM overhead)
```

#### 2.1.2 Native Preset Models (7 Variants from Full Computation)

For native environments, these are **recommended presets** based on full computation testing. Custom configurations are also allowed in developer mode.

**Native Preset Models**:

| Preset Name | depth=7 | depth=8 | depth=9 | Measured Peak RSS | Total Nodes | Use Case |
|-------------|---------|---------|---------|-------------------|-------------|----------|
| **ULTRA_HIGH** | 32M | 64M | 64M | 1,850 MB | ~41M | Research, high-memory servers |
| **HIGH** | 16M | 32M | 32M | 980 MB | ~40M | Production, 1-2GB budget |
| **STANDARD** | 8M | 16M | 16M | 540 MB | ~39M | Default, 700MB-1GB budget |
| **MEDIUM** | 8M | 8M | 8M | 440 MB | ~37M | Memory-constrained |
| **BALANCED** | 4M | 8M | 8M | 290 MB | ~32M | Embedded systems |
| **LOW** | 4M | 4M | 4M | 190 MB | ~24M | Low-memory native |
| **MINIMAL** | 2M | 4M | 4M | 145 MB | ~19M | Extreme constraints |

**Note**: Wide gaps between models (especially HIGH→ULTRA_HIGH: 980MB→1850MB). **Developers should measure and add intermediate models** (e.g., 600MB, 750MB, 1200MB) for better granularity.

#### 2.1.3 Custom Buckets (Native Developer Mode ONLY)

**Constraints**:
1. Bucket sizes must be **powers of 2**: 1M (2²⁰), 2M (2²¹), 4M (2²²), 8M (2²³), 16M (2²⁴), 32M (2²⁵), 64M (2²⁶)
2. Minimum bucket size: **1M** (smaller buckets are inefficient)
3. Maximum bucket size: **64M** (larger buckets risk exceeding 2GB)
4. **Requires ResearchConfig.enable_custom_buckets = true**
5. **No pre-measured RSS** (developer must measure manually)

**Safety Restrictions**:
- **WASM**: Custom buckets **FORBIDDEN** unless `ResearchConfig.high_memory_wasm_mode = true`
- **Native**: Custom buckets allowed in developer/research mode only
- **Rationale**: Prevent accidental OOM crashes in production

**Custom Configuration Example** (Native only):
```cpp
// Native environment, developer mode
BucketConfig cfg;
cfg.model = BucketModel::CUSTOM;
cfg.custom_bucket_7 = 2 << 20;  // 2M
cfg.custom_bucket_8 = 4 << 20;  // 4M
cfg.custom_bucket_9 = 8 << 20;  // 8M

ResearchConfig research;
research.enable_custom_buckets = true;  // Required for custom buckets
research.collect_detailed_statistics = true;  // Measure RSS

xxcross_search solver(true, 6, 1600, true, cfg, research);
// → Outputs: "Custom buckets (2M/4M/8M), estimated ~210 MB, actual RSS: ???"
//   Developer manually validates RSS, then can add to preset list
```

**Adding Validated Custom Config to Presets**:
```cpp
// After validation in research mode:
// 1. Developer confirms RSS ≤ 210 MB (example)
// 2. Add to MEASURED_DATA table:
{BucketModel::CUSTOM_VALIDATED_1, {2<<20, 4<<20, 8<<20, 210, 13, 0.89, 0.66, 0.64}}
// 3. Now users can select it as a preset (no research mode needed)
```

**Notes**:
- Measured on: Ubuntu 22.04, Intel i7-12700K, 32GB RAM, GCC 11.4 -O3
- RSS includes: all C++ runtime overhead, depth 0-6 data, local expansion overhead
- "Total Nodes" = sum of nodes at depth 7, 8, 9
- Bucket sizes use powers of 2 for alignment efficiency

### 2.2 Selection Algorithm

**Three-Mode Selection**:
1. **WASM Auto-Select** (production WASM - preset models only)
2. **Native Auto-Select** (production native - preset models)
3. **Custom Specification** (developer mode only - any power-of-2 combination)

```cpp
enum class BucketModel {
    AUTO,              // Automatic selection based on memory budget
    
    // WASM pre-measured models (13 variants)
    WASM_XS,           // 1M/2M/4M (100 MB)
    WASM_S1,           // 2M/2M/4M (130 MB)
    WASM_S2,           // 2M/4M/4M (145 MB)
    WASM_M1,           // 2M/4M/8M (210 MB)
    WASM_M2,           // 4M/4M/4M (190 MB)
    WASM_M3,           // 4M/8M/8M (290 MB) - Default WASM
    WASM_L1,           // 4M/8M/16M (380 MB)
    WASM_L2,           // 8M/8M/8M (440 MB)
    WASM_L3,           // 8M/16M/16M (540 MB)
    WASM_XL1,          // 8M/16M/32M (720 MB)
    WASM_XL2,          // 16M/16M/16M (650 MB)
    WASM_XL3,          // 16M/32M/32M (980 MB)
    WASM_XXL,          // 32M/32M/32M (1100 MB) - WASM maximum
    
    // Native preset models (7 variants)
    ULTRA_HIGH,        // 32M/64M/64M (1850 MB)
    HIGH,              // 16M/32M/32M (980 MB)
    STANDARD,          // 8M/16M/16M (540 MB)
    MEDIUM,            // 8M/8M/8M (440 MB)
    BALANCED,          // 4M/8M/8M (290 MB)
    LOW,               // 4M/4M/4M (190 MB)
    MINIMAL,           // 2M/4M/4M (145 MB)
    
    CUSTOM,            // User-specified (developer mode only)
    FULL_BFS           // Research mode: no local expansion
};

struct BucketConfig {
    BucketModel model = BucketModel::AUTO;
    
    // For CUSTOM model only (requires ResearchConfig.enable_custom_buckets = true)
    size_t custom_bucket_7 = 0;  // depth=7 bucket size
    size_t custom_bucket_8 = 0;  // depth=8 bucket size  
    size_t custom_bucket_9 = 0;  // depth=9 bucket size
    
    // For AUTO model
    size_t memory_budget_mb = 0;  // If 0, uses constructor's MEMORY_LIMIT_MB
};

BucketConfig select_bucket_model(
    size_t memory_budget_mb, 
    BucketModel user_preference,
    const ResearchConfig& research,
    bool is_wasm_environment) 
{
    // Safety check: Custom buckets require developer mode
    if (user_preference == BucketModel::CUSTOM) {
        if (!research.enable_custom_buckets) {
            throw std::runtime_error(
                "Custom buckets require ResearchConfig.enable_custom_buckets=true");
        }
        
        if (is_wasm_environment && !research.high_memory_wasm_mode) {
            throw std::runtime_error(
                "Custom buckets in WASM require ResearchConfig.high_memory_wasm_mode=true");
        }
        
        // Validate custom buckets
        validate_custom_buckets(cfg.custom_bucket_7, cfg.custom_bucket_8, cfg.custom_bucket_9);
        
        // Estimate RSS and warn if >2GB (unless ignore_memory_limits=true)
        if (!research.ignore_memory_limits) {
            size_t estimated_rss = estimate_rss_from_buckets(
                cfg.custom_bucket_7, cfg.custom_bucket_8, cfg.custom_bucket_9);
            
            if (estimated_rss > 2048) {
                std::cerr << "[ERROR] Custom bucket configuration exceeds 2GB\n";
                std::cerr << "Estimated RSS: " << estimated_rss << " MB\n";
                std::cerr << "Buckets: " << (cfg.custom_bucket_7 >> 20) << "M / "
                          << (cfg.custom_bucket_8 >> 20) << "M / "
                          << (cfg.custom_bucket_9 >> 20) << "M\n";
                std::cerr << "Use ResearchConfig.ignore_memory_limits=true to override\n";
                throw std::runtime_error("Custom buckets exceed 2GB limit");
            }
        }
        
        return cfg;  // Use custom buckets as-is
    }
    
    // Explicit preset selected
    if (user_preference != BucketModel::AUTO) {
        auto preset = get_predefined_model(user_preference);
        
        // Safety: Check if preset exceeds 2GB in WASM (should never happen if table is correct)
        if (is_wasm_environment && !research.high_memory_wasm_mode) {
            if (preset.measured_peak_rss_mb > 1200) {  // Conservative WASM limit
                std::cerr << "[ERROR] Selected model exceeds WASM safe limit\n";
                std::cerr << "Model: " << model_name(user_preference) 
                          << " (" << preset.measured_peak_rss_mb << " MB)\n";
                std::cerr << "WASM safe limit: 1200 MB\n";
                std::cerr << "Use ResearchConfig.high_memory_wasm_mode=true for >1200MB\n";
                throw std::runtime_error("Model exceeds WASM safe limit");
            }
        }
        
        return preset;
    }
    
    // AUTO mode: Select from appropriate preset list
    if (is_wasm_environment) {
        // WASM: Select from WASM-specific models (100 MB intervals)
        return select_wasm_model(memory_budget_mb);
    } else {
        // Native: Select from native preset models
        return select_native_model(memory_budget_mb);
    }
}

// WASM model selection (100 MB intervals)
BucketModel select_wasm_model(size_t memory_budget_mb) {
    if (memory_budget_mb >= 1100) return BucketModel::WASM_XXL;   // 1100 MB
    if (memory_budget_mb >= 980)  return BucketModel::WASM_XL3;   // 980 MB
    if (memory_budget_mb >= 720)  return BucketModel::WASM_XL1;   // 720 MB
    if (memory_budget_mb >= 650)  return BucketModel::WASM_XL2;   // 650 MB
    if (memory_budget_mb >= 540)  return BucketModel::WASM_L3;    // 540 MB
    if (memory_budget_mb >= 440)  return BucketModel::WASM_L2;    // 440 MB
    if (memory_budget_mb >= 380)  return BucketModel::WASM_L1;    // 380 MB
    if (memory_budget_mb >= 290)  return BucketModel::WASM_M3;    // 290 MB (default)
    if (memory_budget_mb >= 210)  return BucketModel::WASM_M1;    // 210 MB
    if (memory_budget_mb >= 190)  return BucketModel::WASM_M2;    // 190 MB
    if (memory_budget_mb >= 145)  return BucketModel::WASM_S2;    // 145 MB
    if (memory_budget_mb >= 130)  return BucketModel::WASM_S1;    // 130 MB
    return BucketModel::WASM_XS;  // 100 MB (minimum)
}

// Native model selection (larger intervals)
BucketModel select_native_model(size_t memory_budget_mb) {
    if (memory_budget_mb >= 1800) return BucketModel::ULTRA_HIGH;  // 1850 MB
    if (memory_budget_mb >= 950)  return BucketModel::HIGH;        // 980 MB
    if (memory_budget_mb >= 520)  return BucketModel::STANDARD;    // 540 MB
    if (memory_budget_mb >= 420)  return BucketModel::MEDIUM;      // 440 MB
    if (memory_budget_mb >= 280)  return BucketModel::BALANCED;    // 290 MB
    if (memory_budget_mb >= 180)  return BucketModel::LOW;         // 190 MB
    return BucketModel::MINIMAL;  // 145 MB
}
```

**Custom Bucket Validation**:
```cpp
void validate_custom_buckets(size_t b7, size_t b8, size_t b9) {
    // Check all are powers of 2
    auto is_power_of_2 = [](size_t n) { return n > 0 && (n & (n - 1)) == 0; };
    
    if (!is_power_of_2(b7) || !is_power_of_2(b8) || !is_power_of_2(b9)) {
        throw std::invalid_argument("Bucket sizes must be powers of 2");
    }
    
    // Check minimum size (1M = 2^20)
    size_t min_size = 1 << 20;
    if (b7 < min_size || b8 < min_size || b9 < min_size) {
        throw std::invalid_argument("Bucket sizes must be >= 1M");
    }
    
    // Check maximum size (64M = 2^26)
    size_t max_size = 64 << 20;
    if (b7 > max_size || b8 > max_size || b9 > max_size) {
        throw std::invalid_argument("Bucket sizes must be <= 64M");
    }
}
```

**Why This Works**:
- **WASM**: Fine-grained control (100MB intervals), guaranteed safety
- **Native**: Coarser presets, more headroom between levels
- **Custom**: Developer responsibility, requires explicit opt-in
- **Safe**: Multi-layer validation prevents accidental OOM

### 2.3 RSS Estimation for Custom Buckets

**Pre-Computed Table** (for preset models only):

```cpp
struct ModelMeasurements {
    size_t bucket_7, bucket_8, bucket_9;
    size_t measured_peak_rss_mb;     // Peak RSS observed in testing
    size_t total_nodes_millions;      // For user reference
    double avg_load_factor_7;         // Observed load factors
    double avg_load_factor_8;
    double avg_load_factor_9;
};

const std::map<BucketModel, ModelMeasurements> MEASURED_DATA = {
    {BucketModel::ULTRA_HIGH, {32<<20, 64<<20, 64<<20, 1850, 156, 0.88, 0.87, 0.65}},
    {BucketModel::HIGH,       {16<<20, 32<<20, 32<<20, 980,  78,  0.89, 0.88, 0.68}},
    {BucketModel::STANDARD,   {8<<20,  16<<20, 16<<20, 540,  39,  0.90, 0.89, 0.70}},
    {BucketModel::MEDIUM,     {8<<20,  8<<20,  8<<20,  440,  23,  0.90, 0.65, 0.63}},
    {BucketModel::BALANCED,   {4<<20,  8<<20,  8<<20,  290,  19,  0.91, 0.88, 0.66}},
    {BucketModel::LOW,        {4<<20,  4<<20,  4<<20,  190,  11,  0.91, 0.67, 0.64}},
    {BucketModel::MINIMAL,    {2<<20,  4<<20,  4<<20,  145,  9,   0.92, 0.68, 0.65}}
};
```

**RSS Estimation Formula** (for CUSTOM buckets):

```cpp
// Conservative estimation for WASM 2GB limit check (no spikes, no margins)
size_t estimate_rss_from_buckets(size_t b7, size_t b8, size_t b9) {
    // Estimate load factors (conservative: use lower bound from measurements)
    double load_7 = 0.88;  // Random expansion typically achieves 0.88-0.92
    double load_8 = 0.65;  // Backtrace expansion with sampling: 0.65-0.88
    double load_9 = 0.63;  // Backtrace expansion: 0.63-0.70
    
    // Calculate expected nodes
    size_t nodes_7 = static_cast<size_t>(b7 * load_7);
    size_t nodes_8 = static_cast<size_t>(b8 * load_8);
    size_t nodes_9 = static_cast<size_t>(b9 * load_9);
    
    // Calculate theoretical memory (robin_set + vectors)
    size_t bucket_memory = (b7 + b8 + b9) * 4;  // 4 bytes per bucket
    size_t node_memory = (nodes_7 + nodes_8 + nodes_9) * 24;  // 24 bytes per node
    size_t vector_memory = (nodes_7 + nodes_8 + nodes_9) * 8;  // 8 bytes per index
    
    size_t theoretical_mb = (bucket_memory + node_memory + vector_memory) / (1024 * 1024);
    
    // Add fixed overhead (depth 0-6 data, C++ runtime, etc.)
    size_t fixed_overhead_mb = 80;  // ~80 MB for BFS phase 1 + runtime
    
    // Simple RSS estimate (no empirical memory factor, no spike margin)
    size_t estimated_rss_mb = theoretical_mb + fixed_overhead_mb;
    
    return estimated_rss_mb;
}
```

**Pre-Computation Table for WASM** (all configs < 2GB):

For production WASM builds, we can pre-compute all 343 possible combinations and filter to those < 2GB:

```cpp
// Generated at build time (example subset)
struct WASMSafeConfig {
    uint8_t b7_shift, b8_shift, b9_shift;  // Powers: 20-26 (1M-64M)
    uint16_t estimated_rss_mb;
};

const std::vector<WASMSafeConfig> WASM_SAFE_CONFIGS = {
    {20, 21, 22, 145},  // 1M/2M/4M → ~145 MB
    {21, 22, 22, 145},  // 2M/4M/4M → ~145 MB (MINIMAL preset)
    {21, 22, 23, 210},  // 2M/4M/8M → ~210 MB
    // ... (50-80 entries total, all < 2048 MB)
    {25, 26, 26, 1850}, // 32M/64M/64M → ~1850 MB (ULTRA_HIGH preset)
    // Configs with any bucket > 64M are excluded (would exceed 2GB)
};

// Fast lookup: O(1) with hash
size_t get_wasm_safe_rss(size_t b7, size_t b8, size_t b9) {
    uint64_t key = (log2(b7) << 16) | (log2(b8) << 8) | log2(b9);
    return WASM_PRECOMPUTED_RSS.at(key);  // Throws if not WASM-safe
}
```

**Usage**:
```cpp
// Preset model
auto measurements = MEASURED_DATA.at(selected_model);
size_t required_mb = measurements.measured_peak_rss_mb;

// Custom model
size_t required_mb = estimate_rss_from_buckets(b7, b8, b9);

// Validate against budget (with 2% C++ margin)
size_t cpp_margin = required_mb * 0.02;
if (memory_budget_mb >= required_mb + cpp_margin) {
    // Safe to proceed
} else {
    // Fallback to smaller config or error
}
```

**Notes**:
- **Preset models**: Use empirical measured RSS (most accurate)
- **Custom models**: Use estimation formula (conservative, safe for WASM)
- **Research mode**: Skip WASM limit check, allow >2GB configurations
- **Pre-computation**: Only for WASM builds, not required for native

---

## 3. Developer Research Mode

### 3.1 Motivation

**Problem**: When developing a new trainer (e.g., EO-Cross, 2x2x2), we don't know:
- How many nodes exist at each depth?
- What's the actual RSS at depth 7? depth 8?
- Is full BFS to depth 8 feasible with 2GB?
- What bucket sizes should we use?

**Current Limitation**: Can't explore because memory limit enforces local expansion.

**Solution**: Research modes that bypass limits.

### 3.2 Research Configuration

```cpp
struct ResearchConfig {
    // Core research modes
    bool enable_local_expansion = true;       // false = full BFS only
    int force_full_bfs_to_depth = -1;         // -1=auto, 7-10=force BFS to this depth
    bool ignore_memory_limits = false;        // true = no budget checks
    bool collect_detailed_statistics = false; // true = per-depth RSS, nodes, time
    bool dry_run = false;                     // true = measure only, don't build database
    
    // Custom bucket controls (safety gates)
    bool enable_custom_buckets = false;       // true = allow CUSTOM bucket model
    bool high_memory_wasm_mode = false;       // true = allow >1200MB in WASM, allow custom buckets in WASM
    
    // Developer memory limit (early theoretical check)
    size_t developer_memory_limit_mb = 2048;  // Warn/block if estimated RSS exceeds this (0 = no limit)
};
```

**Flag Descriptions**:

**enable_custom_buckets**:
- **Default**: `false` (safety)
- **When `true`**: Allows `BucketModel::CUSTOM` with user-specified bucket sizes
- **Purpose**: Prevent accidental OOM from untested configurations
- **Use case**: Developer testing new bucket combinations

**high_memory_wasm_mode**:
- **Default**: `false` (safety)
- **When `true`**: 
  - Allows WASM models >1200 MB (up to 2GB)
  - Allows custom buckets in WASM environment
  - Allows 64M bucket sizes (which may exceed 2GB)
- **Purpose**: Gated access to high-risk configurations
- **Use case**: Developer research on high-memory WASM, server-side WASM with large memory
- **Warning**: Only for experienced developers who understand WASM memory limits

**developer_memory_limit_mb**:
- **Default**: `2048` (2GB limit)
- **Purpose**: Early theoretical check for custom buckets to prevent OOM before allocation
- **When set**: C++ estimates RSS from bucket sizes using theoretical formula (see Section 2.3)
- **If exceeded**: Throws error and exits before allocating buckets (unless `ignore_memory_limits=true`)
- **Use case**: Prevent accidental >2GB allocations from untested bucket configurations
- **Set to 0**: Disable limit check (dangerous, use with `ignore_memory_limits=true`)

**Example Combinations**:

```cpp
// Production WASM (safe defaults)
ResearchConfig prod_wasm;  // All flags = false, limit = 2048 MB
// → Only pre-measured WASM models (145-1100 MB)
// → No custom buckets
// → Automatic safety checks

// Developer testing custom buckets (native)
ResearchConfig dev_native;
dev_native.enable_custom_buckets = true;
dev_native.collect_detailed_statistics = true;
dev_native.developer_memory_limit_mb = 4096;  // Allow up to 4GB for research
// → Allows custom buckets on native
// → Checks 4GB limit (early theoretical check)
// → Collects RSS data for validation

// High-memory WASM research (advanced)
ResearchConfig dev_wasm;
dev_wasm.enable_custom_buckets = true;
dev_wasm.high_memory_wasm_mode = true;
dev_wasm.collect_detailed_statistics = true;
dev_wasm.developer_memory_limit_mb = 1500;  // Conservative WASM limit
// → Allows custom buckets in WASM
// → Allows >1200 MB configurations
// → Early check against 1500 MB limit
// → Developer responsibility for OOM

// Full BFS exploration (unlimited memory)
ResearchConfig full_bfs;
full_bfs.enable_local_expansion = false;
full_bfs.force_full_bfs_to_depth = 8;
full_bfs.ignore_memory_limits = true;
full_bfs.developer_memory_limit_mb = 0;  // Disable limit check
// → No local expansion
// → Full BFS to depth 8
// → No memory budget enforcement
```

### 3.3 Full BFS Validation Mode

**Use Case**: "Can I do full BFS to depth 8 with 2GB RAM?"

```cpp
// Example: Test full BFS to depth 8
ResearchConfig research;
research.enable_local_expansion = false;  // Disable local expansion
research.force_full_bfs_to_depth = 8;
research.ignore_memory_limits = true;     // Let it run until OOM or success
research.collect_detailed_statistics = true;

xxcross_search solver(
    true,    // adj
    8,       // BFS_DEPTH (will attempt full BFS to 8)
    2048,    // MEMORY_LIMIT_MB (informational only with ignore_limits=true)
    true,    // verbose
    BucketConfig{BucketModel::FULL_BFS},
    research
);
```

**Expected Output**:
```
=== Full BFS Research Mode ===
Warning: Local expansion disabled
Warning: Memory limits ignored

Depth 0: 1 nodes, RSS: 15 MB
Depth 1: 18 nodes, RSS: 16 MB
Depth 2: 243 nodes, RSS: 18 MB
Depth 3: 3,007 nodes, RSS: 22 MB
Depth 4: 35,413 nodes, RSS: 35 MB
Depth 5: 391,951 nodes, RSS: 85 MB
Depth 6: 4,123,285 nodes, RSS: 450 MB
Depth 7: 52,413,849 nodes, RSS: 1,247 MB
Depth 8: 348,201,583 nodes, RSS: 8,312 MB  ← Success! But needs 8.3GB

=== Result ===
Full BFS to depth 8: FEASIBLE (requires ~8.3 GB)
Recommendation: Use local expansion for production (STANDARD or HIGH model)
```

### 3.4 Memory Profiling Mode

**Use Case**: "What's the exact RSS curve for this trainer?"

```cpp
ResearchConfig research;
research.enable_local_expansion = false;
research.force_full_bfs_to_depth = 7;  // Stop at 7 (safe)
research.ignore_memory_limits = false;
research.collect_detailed_statistics = true;
research.dry_run = true;  // Don't save to index_pairs (faster)

xxcross_search solver(..., research);
```

**Expected Output** (CSV-style for easy plotting):
```
depth,nodes,rss_mb,theoretical_mb,overhead_mb,time_sec
0,1,15,0,15,0.001
1,18,16,0,16,0.002
2,243,18,0,18,0.010
3,3007,22,0,22,0.050
4,35413,35,1,34,0.300
5,391951,85,9,76,2.100
6,4123285,450,99,351,18.500
7,52413849,1247,1258,-11,145.200
```

**Use**: Import into spreadsheet, plot RSS vs depth, determine optimal bucket sizes.

### 3.5 Implementation Changes

**In `build_complete_search_database()`**:

```cpp
void build_complete_search_database(
    // ... existing params ...
    const ResearchConfig& research = ResearchConfig()  // New parameter
) {
    if (research.ignore_memory_limits) {
        std::cout << "[RESEARCH] Memory limits DISABLED" << std::endl;
        MEMORY_LIMIT_MB = SIZE_MAX;  // Effectively infinite
    }
    
    if (!research.enable_local_expansion) {
        std::cout << "[RESEARCH] Local expansion DISABLED (full BFS only)" << std::endl;
        // Skip Phase 2-4 (local expansion)
        // Force full BFS to research.force_full_bfs_to_depth
    }
    
    if (research.collect_detailed_statistics) {
        std::cout << "depth,nodes,rss_mb,theoretical_mb,overhead_mb,time_sec" << std::endl;
        // Print CSV per depth
    }
    
    if (research.dry_run) {
        // Skip index_pairs.push_back(), only measure
    }
}
```

---

## 4. Memory Margin Strategy

### 4.1 Three-Layer Margin Model

**Layer 1: Measured Peak RSS** (Ground Truth)
- Actual peak RSS observed during testing
- Includes all overhead: C++ runtime, allocator fragmentation, data structures
- **No additional margin needed in C++ code**

**Layer 2: C++ Internal Margin** (2% - Minimal)
- Accounts for minor variations in C++ runtime behavior
- Different allocator implementations (glibc vs musl)
- Small stack frame differences
- **Added in C++ code**: `required_budget = measured_peak_rss * 1.02`

**Layer 3: Environment-Specific Margin** (Caller's Responsibility)
- **WASM**: 20-25% margin (added by JavaScript caller)
- **Embedded**: 15% margin (added by application layer)
- **Server**: 10% margin (added by orchestration system)
- **NOT added in solver_dev.cpp**

### 4.2 Example Calculations

**Scenario 1: Native Linux Application**
```cpp
// C++ side (solver_dev.cpp)
size_t measured_peak = 540;  // MB (STANDARD model)
size_t cpp_margin = 540 * 0.02 = 11;  // MB
size_t required = 540 + 11 = 551;  // MB

// Application side (main.cpp or trainer UI)
size_t user_budget = 700;  // MB (700 - 551 = 149 MB safety)
xxcross_search solver(true, 6, 700, true, BucketConfig{BucketModel::AUTO});
```

**Scenario 2: WebAssembly (WASM)**
```javascript
// JavaScript side (caller)
const measured_peak_mb = 540;  // STANDARD model from C++ docs
const cpp_margin_mb = 540 * 0.02;  // 11 MB
const wasm_margin_mb = 540 * 0.25;  // 135 MB (25% for WASM overhead)
const required_budget_mb = 540 + 11 + 135;  // 686 MB

// Allocate WASM memory
const memory = new WebAssembly.Memory({
    initial: Math.ceil(686 / 65536) * 1024,  // Pages (64KB each)
    maximum: 1024  // 1GB hard cap
});

// Instantiate solver with C++ budget (no WASM margin in C++)
const solver = new Module.xxcross_search(true, 6, 540, false);
```

**Scenario 3: Embedded System**
```cpp
// Embedded application (ARM Cortex-M7, 2MB SRAM)
size_t measured_peak = 145;  // MB (MINIMAL model)
size_t cpp_margin = 145 * 0.02 = 3;  // MB
size_t embedded_margin = 145 * 0.15 = 22;  // MB (15% for RTOS overhead)
size_t total_required = 145 + 3 + 22 = 170;  // MB

if (available_memory_mb >= 170) {
    xxcross_search solver(true, 6, 145, false, BucketConfig{BucketModel::MINIMAL});
}
```

### 4.3 Margin Responsibility Matrix

| Margin Type | Amount | Applied By | Reason |
|-------------|--------|------------|--------|
| **Measured Peak RSS** | 0% | Empirical testing | Ground truth |
| **C++ Internal** | 2% | solver_dev.cpp | Runtime variations |
| **WASM** | 20-25% | JavaScript caller | Memory model overhead |
| **Embedded** | 10-15% | Application layer | RTOS/firmware overhead |
| **Server/Cloud** | 5-10% | Orchestration | Multi-tenant safety |
| **Development** | 50%+ | Developer | Debugging headroom |

**Key Principle**: **C++ code is margin-agnostic**. It trusts measured data. Callers add environment-specific margins.

---

## 5. Memory Spike Elimination

### 5.1 Current Spike Sources

**Problem 1: Vector Reallocation**
```cpp
// Old code (causes spike)
index_pairs[depth].push_back(node);  // Realloc if capacity exceeded
// Spike: 2x current vector size temporarily
```

**Problem 2: robin_hash Rehashing**
```cpp
// During robin_set growth
robin_set.insert(node);  // Triggers rehash
// Spike: Old buckets + new buckets simultaneously
```

**Problem 3: Element Vector Attachment**
```cpp
// Potential issue in attach_element_vector()
robin_set.attach_element_vector(&vec);
// If vec grows without reserve, causes spike
```

### 5.2 Elimination Strategies

#### Strategy 1: Pre-Reserve ALL Vectors

**Critical Insight**: From code review, **most vectors lack reserve() calls**. This causes frequent reallocations and memory spikes.

**Systematic Reserve Policy**:

```cpp
// Step 1: Calculate maximum capacity from load factors and bucket sizes
size_t max_nodes_7 = static_cast<size_t>(bucket_7 * load_factor_7 * 1.05);  // +5% safety
size_t max_nodes_8 = static_cast<size_t>(bucket_8 * load_factor_8 * 1.05);
size_t max_nodes_9 = static_cast<size_t>(bucket_9 * load_factor_9 * 1.05);

// Step 2: Reserve index_pairs vectors BEFORE any insertions
index_pairs[7].reserve(max_nodes_7);
index_pairs[8].reserve(max_nodes_8);
index_pairs[9].reserve(max_nodes_9);

// Step 3: Reserve vectors used with attach_element_vector()
std::vector<uint64_t> depth_7_vector;
depth_7_vector.reserve(max_nodes_7);  // CRITICAL: Reserve before attach
depth_7_nodes.attach_element_vector(&depth_7_vector);

// Step 4: Reserve temporary vectors
std::vector<uint64_t> sampled_parents;
sampled_parents.reserve(max_nodes_8 / 12);  // 1/12 sampling rate
```

**Load Factor Based Capacity Calculation**:
```cpp
// From measured data, we know empirical load factors:
// - Random expansion (depth 7): 0.88-0.92 → use 0.88 (conservative)
// - Backtrace expansion (depth 8): 0.65-0.88 → use 0.65
// - Backtrace expansion (depth 9): 0.63-0.70 → use 0.63

double get_expected_load_factor(int depth, ExpansionType type) {
    if (type == ExpansionType::RANDOM) {
        return 0.88;  // Random parent selection achieves high load
    } else {  // BACKTRACE
        return (depth == 8) ? 0.65 : 0.63;  // Lower due to filtering
    }
}

size_t calculate_max_capacity(size_t bucket_size, int depth, ExpansionType type) {
    double load = get_expected_load_factor(depth, type);
    return static_cast<size_t>(bucket_size * load * 1.05);  // +5% headroom
}
```

**Complete Reserve Checklist** (solver_dev.cpp audit):

- [ ] `index_pairs[0-9]` - Reserve based on BFS/local expansion estimates
- [ ] `depth_7_vector` - Reserve `bucket_7 * 0.88 * 1.05` BEFORE attach
- [ ] `depth_8_vector` - Reserve `bucket_8 * 0.65 * 1.05` BEFORE attach
- [ ] `depth_9_vector` - Reserve `bucket_9 * 0.63 * 1.05` BEFORE attach
- [ ] `sampled_parents` - Reserve `expected_n1_nodes / 12`
- [ ] `depth_n_vec` (in random expansion) - Reserve `depth_n_nodes.size()`
- [ ] Any temporary vectors created in loops - Reserve before use

**Estimation for Phase 1 (depth 0-6)**:
```cpp
const size_t PHASE1_ESTIMATED_NODES[] = {
    1,          // depth 0
    18,         // depth 1
    243,        // depth 2
    3'007,      // depth 3
    35'413,     // depth 4
    391'951,    // depth 5
    4'123'285,  // depth 6 (exact count known)
};

for (int d = 0; d <= 6; ++d) {
    index_pairs[d].reserve(PHASE1_ESTIMATED_NODES[d]);
}
```

#### Strategy 2: Prevent robin_hash Rehash (Already Implemented)

**Status**: ✅ **Already correctly implemented** in solver_dev.cpp

```cpp
// Existing code already prevents rehash during expansion:
while (!depth_n1_nodes.will_rehash_on_next_insert()) {
    depth_n1_nodes.insert(child_node);
}
```

**Verification Checklist**:
- [x] Random expansion (depth n→n+1): Uses `will_rehash_on_next_insert()` guard
- [x] Backtrace expansion (depth n+1→n+2): Uses `will_rehash_on_next_insert()` guard  
- [x] Pre-allocation: Calls `robin_set.rehash(bucket_size)` before expansion

**Key Insight**: robin_hash core is **already highly optimized** (fast, spike-free). The issue is our **custom features** (attach_element_vector) and **caller code** (vector usage), not robin_hash itself.

**No Changes Needed**: Core robin_hash logic is sound.

#### Strategy 3: Fix attach_element_vector() Usage (CRITICAL)

**Current Implementation** (in tsl/robin_hash.h):
```cpp
void attach_element_vector(std::vector<value_type>* vec) {
    m_element_vector = vec;  // Just store pointer, no reserve
}

// In insert_impl() - called for EVERY successful insertion:
if (m_element_vector != nullptr) {
    m_element_vector->push_back(key);  // ← SPIKE SOURCE if not pre-reserved!
}
```

**Problem Analysis**:

1. **attach_element_vector() does NOT reserve** - only stores pointer
2. **Every insert() calls push_back()** - can trigger vector reallocation
3. **Vector reallocation is O(n)** - copies all existing elements
4. **Memory spike** = old vector + new vector (2x current size)

**Example Spike Scenario**:
```cpp
// BAD: No reserve
std::vector<uint64_t> vec;  // capacity = 0
robin_set.attach_element_vector(&vec);

for (int i = 0; i < 10'000'000; ++i) {
    robin_set.insert(i);  // push_back() triggers realloc at 1, 2, 4, 8, 16, ...
}
// Spike at 8.3M elements: old 8.3M + new 16.6M = 25M elements = 200 MB spike!
```

**Solution: Mandatory Pre-Reserve in Caller**

```cpp
// GOOD: Pre-reserve to maximum expected capacity
std::vector<uint64_t> depth_7_vector;
size_t max_capacity = static_cast<size_t>(bucket_7 * 0.88 * 1.05);  // +5% safety
depth_7_vector.reserve(max_capacity);  // ← CRITICAL: MUST reserve before attach

robin_set.attach_element_vector(&depth_7_vector);
// Now all push_back() calls are O(1), no reallocation, no spike
```

**Verification**:
```cpp
// After attach, verify capacity
assert(depth_7_vector.capacity() >= max_capacity);

// After expansion, verify no reallocation occurred
assert(depth_7_vector.capacity() == max_capacity);  // Should not have grown
```

**Code Audit Required** (solver_dev.cpp):

Search for all `attach_element_vector()` calls and ensure preceding `reserve()`:

```bash
$ grep -B 2 "attach_element_vector" solver_dev.cpp
```

**Fix Pattern**:
```cpp
// BEFORE (spike risk):
robin_set.attach_element_vector(&vec);

// AFTER (spike-free):
vec.reserve(calculate_max_capacity(...));
robin_set.attach_element_vector(&vec);
```

**Alternative: API Enhancement** (future consideration):
```cpp
// Optional enhancement to robin_hash.h (not required if callers follow pattern)
void attach_element_vector(std::vector<value_type>* vec, size_t reserve_hint) {
    m_element_vector = vec;
    if (reserve_hint > 0 && m_element_vector->capacity() < reserve_hint) {
        m_element_vector->reserve(reserve_hint);
    }
}
```

**Decision**: **Caller responsibility** (Solution 1) is clearer and more explicit. The caller knows the expected capacity better than robin_hash.

#### Strategy 4: Avoid Temporary Allocations

**Anti-Pattern** (spike risk):
```cpp
// Creates temporary vector
std::vector<uint64_t> temp = {begin, end};  // COPY spike
process(temp);
```

**Correct Pattern**:
```cpp
// Use references or move semantics
std::vector<uint64_t> temp;
temp.reserve(std::distance(begin, end));
for (auto it = begin; it != end; ++it) {
    temp.push_back(*it);  // No spike (pre-reserved)
}
process(std::move(temp));  // Move, not copy
```

### 5.3 Spike Elimination Checklist

For `solver_dev.cpp` code review:

- [ ] All `index_pairs[d]` vectors pre-reserved before BFS
- [ ] All `robin_set.insert()` loops use `will_rehash_on_next_insert()` guard
- [ ] All `attach_element_vector()` calls pre-reserve the target vector
- [ ] No vector copy constructors in hot paths (use `std::move()`)
- [ ] No vector range assignments without reserve (use `reserve()` + `insert()`)
- [ ] Temporary vectors are avoided or pre-sized
- [ ] `shrink_to_fit()` called after final size known (reclaim excess)

**Testing**: Run with memory profiler (Valgrind, Heaptrack) to verify no spikes >5% of steady-state RSS.

---

## 6. WebAssembly Specifics

### 6.1 WASM Model System Philosophy

**Why Pre-Measured Models Only?**

Unlike native environments with swap and OS memory management, WebAssembly has **hard memory limits**:

- Browser enforces strict allocation ceiling (typically 1-2 GB)
- No swap, no overcommit - OOM = instant crash
- Memory growth is expensive (browser must find contiguous virtual space)

Therefore, WASM uses **only pre-measured models** with verified RSS data. Custom buckets are developer-mode only.

**Design Principles**:

1. **Safety First**: Every WASM model is tested to guaranteed peak RSS
2. **User Simplicity**: User specifies budget (MB), C++ auto-selects safe model
3. **JavaScript Responsibility**: JS adds 25% WASM margin, C++ uses raw RSS
4. **Developer Freedom**: High-memory mode allows >1200MB and custom (at own risk)

### 6.2 Memory Allocation Flow

**JavaScript Side** (WASM wrapper):

```javascript
class RubiksSolverWASM {
    constructor(memoryBudgetMB = 300) {
        // Step 1: User specifies total budget (e.g., 300 MB)
        this.userBudget = memoryBudgetMB;
        
        // Step 2: Subtract WASM margin (25% for browser overhead, GC, etc.)
        const WASM_MARGIN_RATIO = 0.75;  // Reserve 25% for WASM overhead
        const cppBudgetMB = Math.floor(this.userBudget * WASM_MARGIN_RATIO);
        
        // Step 3: Allocate WASM memory with user's total budget (max 2GB = 2048 MB)
        const initialPages = Math.min(
            Math.ceil(this.userBudget / 64),  // 64 MB per page
            32768  // 2 GB max
        );
        
        this.wasmMemory = new WebAssembly.Memory({
            initial: initialPages,
            maximum: 32768  // 2 GB hard limit
        });
        
        // Step 4: C++ receives budget after subtracting WASM margin
        // C++ will select model ≤ cppBudgetMB (e.g., 225 MB → BALANCED = 190 MB)
        this.solver = new Module.xxcross_search(
            true,            // adj
            6,               // BFS_DEPTH
            cppBudgetMB,     // C++ sees 225 MB (300 * 0.75)
            false            // verbose (browser = no console spam)
        );
        
        console.log(`User budget: ${this.userBudget} MB, C++ budget: ${cppBudgetMB} MB (75% of total)`);
    }
}

// Example: User has 400 MB budget
const solver = new RubiksSolverWASM(400);
// → JS allocates 400 MB WASM memory
// → C++ receives 400 * 0.75 = 300 MB budget
// → C++ selects BALANCED (290 MB measured RSS)
// → Actual peak: ~290 MB + 2% margin = 296 MB
// → Safe margin: 400 - 296 = 104 MB (26% headroom for WASM overhead)
```

**C++ Side** (solver constructor):

```cpp
xxcross_search::xxcross_search(bool adj, int BFS_DEPTH, int MEMORY_LIMIT_MB, bool verbose,
                               const BucketConfig& cfg, const ResearchConfig& research) {
    // Step 1: Validate WASM environment
    #ifdef __EMSCRIPTEN__
        if (!research.high_memory_wasm_mode) {
            const size_t WASM_SAFE_LIMIT_MB = 1200;  // Conservative WASM ceiling
            if (MEMORY_LIMIT_MB > WASM_SAFE_LIMIT_MB) {
                throw std::runtime_error(
                    "WASM safe limit exceeded: " + std::to_string(MEMORY_LIMIT_MB) + " MB > " +
                    std::to_string(WASM_SAFE_LIMIT_MB) + " MB. Use ResearchConfig.high_memory_wasm_mode=true if intentional."
                );
            }
        }
    #endif
    
    // Step 2: Select model (WASM-specific auto-selection)
    BucketModel model = cfg.model;
    if (model == BucketModel::AUTO) {
        #ifdef __EMSCRIPTEN__
            model = select_wasm_model(MEMORY_LIMIT_MB);  // 100MB interval granularity
        #else
            model = select_native_model(MEMORY_LIMIT_MB);  // Coarser intervals
        #endif
    }
    
    // Step 3: Validate model safety
    validate_model_safety(model, MEMORY_LIMIT_MB, research);
    
    // Step 4: Initialize buckets
    const auto& data = MEASURED_DATA.at(model);
    init_buckets(data.d7, data.d8, data.d9);
}
```

### 6.3 WASM Safety Checks

```cpp
void validate_model_safety(BucketModel model, size_t budget_mb, const ResearchConfig& cfg) {
    // Check 1: Custom buckets require explicit flag
    if (model == BucketModel::CUSTOM && !cfg.enable_custom_buckets) {
        throw std::runtime_error(
            "CUSTOM model requires ResearchConfig.enable_custom_buckets=true"
        );
    }
    
    // Check 2: WASM-specific checks
    #ifdef __EMSCRIPTEN__
        const size_t WASM_SAFE_LIMIT_MB = 1200;
        
        // Check 2a: Custom buckets in WASM require high-memory mode
        if (model == BucketModel::CUSTOM && !cfg.high_memory_wasm_mode) {
            throw std::runtime_error(
                "CUSTOM model in WASM requires ResearchConfig.high_memory_wasm_mode=true"
            );
        }
        
        // Check 2b: Validate model RSS against WASM safe limit
        if (MEASURED_DATA.count(model) > 0) {
            size_t measured_rss = MEASURED_DATA.at(model).measured_rss_mb;
            if (measured_rss > WASM_SAFE_LIMIT_MB && !cfg.high_memory_wasm_mode) {
                throw std::runtime_error(
                    "Model " + to_string(model) + " exceeds WASM safe limit (" +
                    std::to_string(measured_rss) + " MB > " + std::to_string(WASM_SAFE_LIMIT_MB) +
                    " MB). Use high_memory_wasm_mode=true or select smaller model."
                );
            }
        }
    #endif
    
    // Check 3: Custom buckets RSS estimation (>2GB check)
    if (model == BucketModel::CUSTOM) {
        // Early theoretical calculation to predict memory usage
        // Formula: RSS ≈ (d7_bucket * 0.9) + (d8_bucket * 0.9) + (d9_bucket * 0.75) + base_overhead
        size_t estimated_rss_mb = estimate_custom_rss(cfg.custom_bucket_7, 
                                                       cfg.custom_bucket_8, 
                                                       cfg.custom_bucket_9);
        
        // Developer memory limit (configurable, default 2GB)
        const size_t DEVELOPER_LIMIT_MB = cfg.developer_memory_limit_mb > 0 
                                        ? cfg.developer_memory_limit_mb 
                                        : 2048;  // Default 2GB
        
        if (estimated_rss_mb > DEVELOPER_LIMIT_MB && !cfg.ignore_memory_limits) {
            throw std::runtime_error(
                "Custom buckets exceed developer limit (estimated: " +
                std::to_string(estimated_rss_mb) + " MB > " + 
                std::to_string(DEVELOPER_LIMIT_MB) + " MB). " +
                "Reduce bucket sizes or set ignore_memory_limits=true."
            );
        }
        
        // Warn if close to limit (>90%)
        if (estimated_rss_mb > DEVELOPER_LIMIT_MB * 0.9) {
            std::cerr << "WARNING: Estimated RSS (" << estimated_rss_mb 
                      << " MB) is close to limit (" << DEVELOPER_LIMIT_MB << " MB)\n";
        }
    }
}

// Theoretical RSS estimation (early check before allocation)
size_t estimate_custom_rss(size_t d7_bucket, size_t d8_bucket, size_t d9_bucket) {
    // Conservative estimates based on empirical load factors
    const double LOAD_D7 = 0.90;  // depth 7 typical load
    const double LOAD_D8 = 0.89;  // depth 8 typical load  
    const double LOAD_D9 = 0.70;  // depth 9 typical load
    const size_t BASE_OVERHEAD_MB = 50;  // Solver overhead, vectors, etc.
    
    size_t d7_rss = (d7_bucket >> 20) * LOAD_D7;  // Convert to MB
    size_t d8_rss = (d8_bucket >> 20) * LOAD_D8;
    size_t d9_rss = (d9_bucket >> 20) * LOAD_D9;
    
    return d7_rss + d8_rss + d9_rss + BASE_OVERHEAD_MB;
}
```

### 6.4 WASM Model Table Implementation

**C++ Measured Data** (header file):

```cpp
// wasm_models.h - Pre-measured WASM models
#pragma once

#include <unordered_map>

enum class BucketModel {
    // ... (same as Section 7.1)
};

struct ModelData {
    size_t d7, d8, d9;           // Bucket sizes (bytes)
    size_t measured_rss_mb;      // Peak RSS in MB (no margin)
    size_t total_nodes_million;  // Total nodes explored (debugging)
    double load_d7, load_d8, load_d9;  // Load factors (debugging)
};

// Note: Wide gaps between models, especially >1GB. Developers should measure and add
// intermediate models (e.g., 600MB, 750MB) to improve granularity.
const std::unordered_map<BucketModel, ModelData> MEASURED_DATA = {
    // Preset models (7 variants from full computation)
    {BucketModel::MINIMAL,    {2<<20, 4<<20, 4<<20,   145, 19, 0.88, 0.83, 0.68}},
    {BucketModel::LOW,        {4<<20, 4<<20, 4<<20,   190, 24, 0.90, 0.86, 0.69}},
    {BucketModel::BALANCED,   {4<<20, 8<<20, 8<<20,   290, 32, 0.92, 0.88, 0.73}},  // Default
    {BucketModel::MEDIUM,     {8<<20, 8<<20, 8<<20,   440, 37, 0.93, 0.90, 0.74}},
    {BucketModel::STANDARD,   {8<<20, 16<<20, 16<<20, 540, 39, 0.94, 0.91, 0.76}},
    {BucketModel::HIGH,       {16<<20, 32<<20, 32<<20, 980, 40, 0.95, 0.92, 0.79}},
    
    // ULTRA_HIGH: Different bucket sizes for WASM vs Native (runtime detection)
    // WASM: 32M/32M/32M (~1100 MB) - Maximum safe
    // Native: 32M/64M/64M (~1850 MB) - Higher capacity
};

// ULTRA_HIGH model uses runtime environment detection
ModelData get_ultra_high_config() {
    #ifdef __EMSCRIPTEN__
        return {32<<20, 32<<20, 32<<20, 1100, 41, 0.96, 0.93, 0.80};  // WASM safe
    #else
        return {32<<20, 64<<20, 64<<20, 1850, 41, 0.96, 0.93, 0.81};  // Native high-capacity
    #endif
}

BucketModel select_model(size_t budget_mb) {
    // Select largest model ≤ budget (same for WASM and Native, except ULTRA_HIGH)
    if (budget_mb >= 1100) return BucketModel::ULTRA_HIGH;  // WASM: 1100 MB, Native: 1850 MB
    if (budget_mb >= 980)  return BucketModel::HIGH;        // 980 MB
    if (budget_mb >= 540)  return BucketModel::STANDARD;    // 540 MB
    if (budget_mb >= 440)  return BucketModel::MEDIUM;      // 440 MB
    if (budget_mb >= 290)  return BucketModel::BALANCED;    // 290 MB (default)
    if (budget_mb >= 190)  return BucketModel::LOW;         // 190 MB
    return BucketModel::MINIMAL;  // 145 MB (minimum)
    
    // Note: Large gap between HIGH (980 MB) and ULTRA_HIGH (1100/1850 MB)
    // Developers should add intermediate models for better granularity
}
```

### 6.5 Production WASM Example

**HTML Page**:

```html
<!DOCTYPE html>
<html>
<head>
    <title>Rubik's Cube Solver (WASM)</title>
</head>
<body>
    <h1>Rubik's Cube Solver</h1>
    
    <!-- User controls -->
    <label>Memory Budget (MB):</label>
    <input type="range" id="memorySlider" min="100" max="1000" value="300" step="50">
    <span id="memoryValue">300 MB</span>
    
    <button id="solveButton">Solve Scramble</button>
    <div id="output"></div>
    
    <script src="solver.js"></script>
    <script>
        // Step 1: User adjusts memory budget
        const slider = document.getElementById('memorySlider');
        const valueLabel = document.getElementById('memoryValue');
        
        slider.addEventListener('input', (e) => {
            valueLabel.textContent = `${e.target.value} MB`;
        });
        
        // Step 2: Solve with selected budget
        document.getElementById('solveButton').addEventListener('click', async () => {
            const userBudget = parseInt(slider.value);
            
            // JavaScript subtracts WASM margin (25% reserved for overhead)
            const cppBudget = Math.floor(userBudget * 0.75);
            
            // Load WASM module
            const Module = await import('./solver_wasm.js');
            await Module.ready;
            
            console.log(`User budget: ${userBudget} MB`);
            console.log(`C++ budget: ${cppBudget} MB (75% of total, 25% reserved for WASM)`);
            
            // C++ receives budget after margin subtracted
            const solver = new Module.xxcross_search(
                true,        // adj
                6,           // BFS_DEPTH
                cppBudget,   // Memory budget (C++ auto-selects model)
                false        // verbose (browser)
            );
            
            // Solve scramble
            const scramble = "R U R' U' R' F R2 U' R' U' R U R' F'";
            const solutions = solver.solve(scramble);
            
            document.getElementById('output').innerHTML = 
                `<h3>Solutions:</h3><pre>${solutions.join('\n')}</pre>` +
                `<p>Peak memory: ~${userBudget} MB (estimated)</p>`;
            
            solver.delete();
        });
    </script>
</body>
</html>
```

**Key Points**:
1. User sees only memory budget slider (100-1000 MB)
2. JavaScript adds 25% WASM margin automatically
3. C++ auto-selects safe pre-measured model
4. No custom buckets exposed in production UI
5. Developer mode requires explicit flags (not accessible from browser UI)

---

## 7. Implementation Guidelines

### 7.1 Constructor API Changes

**New Constructor Signature**:

```cpp
struct xxcross_search {
    xxcross_search(
        bool adj = true,
        int BFS_DEPTH = 6,
        int MEMORY_LIMIT_MB = 1600,
        bool verbose = true,
        const BucketConfig& bucket_config = BucketConfig(),      // NEW
        const ResearchConfig& research_config = ResearchConfig() // NEW
    );
};
```

**Default Behavior** (backwards compatible):
```cpp
// Old code still works
xxcross_search solver(true, 6, 1600, true);
// Uses BucketConfig{BucketModel::AUTO} → selects STANDARD (540 MB)
```

**Explicit Model Selection**:
```cpp
// Force HIGH model
BucketConfig cfg;
cfg.model = BucketModel::HIGH;
xxcross_search solver(true, 6, 1600, true, cfg);
```

**Research Mode**:
```cpp
// Full BFS test
ResearchConfig research;
research.enable_local_expansion = false;
research.force_full_bfs_to_depth = 8;
xxcross_search solver(true, 8, 4096, true, 
    BucketConfig{BucketModel::FULL_BFS}, research);
```

### 6.2 Migration from Old Code

**Step 1: Replace `determine_bucket_sizes()`**

```cpp
// OLD (delete this function):
LocalExpansionConfig determine_bucket_sizes(
    int max_depth,
    size_t remaining_memory_bytes,
    size_t bucket_n_current,
    size_t cur_set_memory_bytes,
    bool verbose
);

// NEW (simple switch):
BucketModel select_model_from_budget(size_t memory_budget_mb) {
    if (memory_budget_mb >= 1800) return BucketModel::ULTRA_HIGH;
    if (memory_budget_mb >= 950)  return BucketModel::HIGH;
    if (memory_budget_mb >= 520)  return BucketModel::STANDARD;
    if (memory_budget_mb >= 420)  return BucketModel::MEDIUM;
    if (memory_budget_mb >= 280)  return BucketModel::BALANCED;
    if (memory_budget_mb >= 180)  return BucketModel::LOW;
    return BucketModel::MINIMAL;
}

LocalExpansionConfig get_model_config(BucketModel model) {
    auto& data = MEASURED_DATA.at(model);
    LocalExpansionConfig cfg;
    cfg.bucket_n1 = data.bucket_7;
    cfg.bucket_n2 = data.bucket_8;
    cfg.enable_n1_expansion = true;
    cfg.enable_n2_expansion = (data.bucket_9 > 0);
    return cfg;
}
```

**Step 2: Update `build_complete_search_database()`**

```cpp
// Add research_config parameter
void build_complete_search_database(
    // ... existing params ...
    const ResearchConfig& research_config = ResearchConfig()
) {
    // Handle research modes
    if (!research_config.enable_local_expansion) {
        // Skip Phase 2-4, do full BFS only
        return;
    }
    
    if (research_config.ignore_memory_limits) {
        MEMORY_LIMIT_MB = SIZE_MAX / (1024 * 1024);  // Effectively unlimited
    }
    
    // ... rest of implementation
}
```

**Step 3: Pre-Reserve All Vectors**

```cpp
// In Phase 1 setup
auto model = select_model_from_budget(MEMORY_LIMIT_MB);
auto& measurements = MEASURED_DATA.at(model);

// Reserve based on model
index_pairs[7].reserve(static_cast<size_t>(measurements.bucket_7 * 
                       measurements.avg_load_factor_7 * 1.1));
index_pairs[8].reserve(static_cast<size_t>(measurements.bucket_8 * 
                       measurements.avg_load_factor_8 * 1.1));
index_pairs[9].reserve(static_cast<size_t>(measurements.bucket_9 * 
                       measurements.avg_load_factor_9 * 1.1));
```

### 6.3 Validation Testing

**Test Suite Requirements**:

1. **Model Selection Test**
   - Input: 200 MB budget → Output: MINIMAL model
   - Input: 700 MB budget → Output: STANDARD model
   - Input: 2000 MB budget → Output: ULTRA_HIGH model

2. **Research Mode Test**
   - Full BFS to depth 7 completes without crash
   - CSV output matches expected format
   - `dry_run=true` skips database construction

3. **Memory Spike Test**
   - Monitor RSS every 100ms during construction
   - Assert: `max(rss_spikes) - steady_state_rss < steady_state_rss * 0.05`
   - If spike >5%, identify source and fix

4. **Margin Test**
   - STANDARD model with 540 MB limit → actual RSS ≤ 551 MB (2% margin)
   - Verify no OOM even at exact measured peak

---

## 7. API Reference

### 7.1 Enums

```cpp
enum class BucketModel {
    AUTO,              // Automatic selection based on environment and memory budget
    
    // Preset models (7 variants, shared by WASM and Native)
    // Note: Wide gaps between models (especially >1GB) - developers should add intermediate models
    MINIMAL,           // 2M/4M/4M (~145 MB)
    LOW,               // 4M/4M/4M (~190 MB)
    BALANCED,          // 4M/8M/8M (~290 MB) - Default
    MEDIUM,            // 8M/8M/8M (~440 MB)
    STANDARD,          // 8M/16M/16M (~540 MB)
    HIGH,              // 16M/32M/32M (~980 MB)
    ULTRA_HIGH,        // WASM: 32M/32M/32M (~1100 MB), Native: 32M/64M/64M (~1850 MB)
    
    CUSTOM,            // User-specified (requires enable_custom_buckets=true)
    FULL_BFS           // Research mode: no local expansion
};
```

### 7.2 Structs

```cpp
struct BucketConfig {
    BucketModel model = BucketModel::AUTO;
    
    // For CUSTOM model (requires ResearchConfig.enable_custom_buckets = true)
    size_t custom_bucket_7 = 0;  // Must be power of 2 (1M-64M)
    size_t custom_bucket_8 = 0;
    size_t custom_bucket_9 = 0;
    
    // For AUTO model (optional override)
    size_t memory_budget_mb = 0;  // 0 = use constructor's MEMORY_LIMIT_MB
};

struct ResearchConfig {
    // Core research modes
    bool enable_local_expansion = true;       // false = full BFS only
    int force_full_bfs_to_depth = -1;         // -1=auto, 7-10=force
    bool ignore_memory_limits = false;        // true = no budget enforcement
    bool collect_detailed_statistics = false; // true = CSV output per depth
    bool dry_run = false;                     // true = measure only, no DB
    
    // Safety gates (developer mode)
    bool enable_custom_buckets = false;       // true = allow CUSTOM model
    bool high_memory_wasm_mode = false;       // true = allow >1200MB WASM, custom buckets in WASM
    
    // Developer memory limit (early theoretical check)
    size_t developer_memory_limit_mb = 2048;  // Warn/block if estimated RSS exceeds (0 = no limit)
};
    bool enable_custom_buckets = false;       // true = allow CUSTOM model
    bool high_memory_wasm_mode = false;       // true = allow >1200MB WASM, custom buckets in WASM
};
```

### 7.3 Constructor

```cpp
xxcross_search::xxcross_search(
    bool adj = true,                                // Adjacent (true) or opposite (false) slots
    int BFS_DEPTH = 6,                              // Full BFS depth (usually 6)
    int MEMORY_LIMIT_MB = 1600,                     // Memory budget (MB)
    bool verbose = true,                            // Print progress logs
    const BucketConfig& bucket_config = {},         // Bucket allocation config
    const ResearchConfig& research_config = {}      // Developer research mode
);
```

**Examples**:

```cpp
// Example 1: Production WASM (automatic model selection)
// JavaScript: user specifies 300 MB, JS subtracts 25% margin → 225 MB to C++
xxcross_search solver1(true, 6, 225, false);  // C++ auto-selects LOW (190 MB)
// → Safe, pre-measured, guaranteed to fit in 300 MB total budget

// Example 2: Native auto-select
xxcross_search solver2(true, 6, 700, true);
// → Selects STANDARD model (540 MB measured)

// Example 3: Explicit model (user knows what they want)
BucketConfig cfg3;
cfg3.model = BucketModel::STANDARD;  // Force 8M/16M/16M (540 MB)
xxcross_search solver3(true, 6, 540, false, cfg3);
// → Uses exactly STANDARD, no auto-selection

// Example 4: Custom buckets (native developer mode)
BucketConfig cfg4;
cfg4.model = BucketModel::CUSTOM;
cfg4.custom_bucket_7 = 2 << 20;  // 2M
cfg4.custom_bucket_8 = 4 << 20;  // 4M
cfg4.custom_bucket_9 = 8 << 20;  // 8M

ResearchConfig research4;
research4.enable_custom_buckets = true;  // Required for custom
research4.collect_detailed_statistics = true;

xxcross_search solver4(true, 6, 1600, true, cfg4, research4);
// → Uses custom 2M/4M/8M, collects RSS data
// → Developer validates RSS, can add to preset list if stable

// Example 5: High-memory WASM research (DANGEROUS - advanced only)
BucketConfig cfg5;
cfg5.model = BucketModel::ULTRA_HIGH;  // WASM: 32M/32M/32M (1100 MB)

ResearchConfig research5;
research5.high_memory_wasm_mode = true;  // Bypass 1200MB WASM limit

xxcross_search solver5(true, 6, 1100, true, cfg5, research5);
// → Allowed only with high_memory_wasm_mode flag
// → Developer responsibility for OOM

// Example 6: Full BFS exploration (unlimited memory)
ResearchConfig research6;
research6.enable_local_expansion = false;
research6.force_full_bfs_to_depth = 8;
research6.ignore_memory_limits = true;

xxcross_search solver6(true, 8, 4096, true, 
    BucketConfig{BucketModel::FULL_BFS}, research6);
// → Full BFS to depth 8, no memory limits
// → Outputs exact node counts and RSS per depth

// Example 7: FORBIDDEN - custom buckets in WASM without flags
BucketConfig cfg7;
cfg7.model = BucketModel::CUSTOM;
cfg7.custom_bucket_7 = 4 << 20;

// This will throw:
xxcross_search solver7(true, 6, 300, false, cfg7);  
// ERROR: "Custom buckets require ResearchConfig.enable_custom_buckets=true"

// Example 8: FORBIDDEN - high-memory model in WASM without flag
BucketConfig cfg8;
cfg8.model = BucketModel::ULTRA_HIGH;  // 1850 MB > 1200 MB WASM limit

// This will throw:
xxcross_search solver8(true, 6, 1850, false, cfg8);
// ERROR: "Model exceeds WASM safe limit (1850 MB > 1200 MB)"
```

---

## 8. Empirical Data Collection

### 8.1 Measurement Protocol

To update `MEASURED_DATA` table (e.g., new compiler, new platform):

**Environment**:
- OS: Ubuntu 22.04 LTS (or specify)
- CPU: Intel i7-12700K (or specify)
- RAM: 32 GB (ensure no swap)
- Compiler: GCC 11.4 -O3 -march=native
- Date: 2026-01-01

**Procedure**:
1. Enable research mode:
   ```cpp
   ResearchConfig cfg;
   cfg.collect_detailed_statistics = true;
   ```

2. Run each model and record peak RSS:
   ```bash
   for model in ULTRA_HIGH HIGH STANDARD MEDIUM BALANCED LOW MINIMAL; do
       ./solver_test --model=$model --verbose | tee log_$model.txt
       # Extract "RSS after depth 9" line
   done
   ```

3. Update table:
   ```cpp
   {BucketModel::STANDARD, {8<<20, 16<<20, 16<<20, 540, 39, 0.90, 0.89, 0.70}}
   //                                                 ^^^  ^^  ^^^^  ^^^^  ^^^^
   //                                                 │    │   │     │     └─ depth 9 load
   //                                                 │    │   │     └─ depth 8 load
   //                                                 │    │   └─ depth 7 load
   //                                                 │    └─ total nodes (millions)
   //                                                 └─ measured peak RSS (MB)
   ```

4. Validate on 10 runs, ensure <2% variance

### 8.2 Load Factor Calibration

**Why Measure Load Factors?**
- Predict actual node count from bucket size
- Validate that random expansion achieves high utilization
- Detect if new compiler/platform changes hash behavior

**Collection**:
```cpp
// After expansion complete
double load_7 = (double)depth_7_nodes.size() / depth_7_nodes.bucket_count();
double load_8 = (double)depth_8_nodes.size() / depth_8_nodes.bucket_count();
double load_9 = (double)depth_9_nodes.size() / depth_9_nodes.bucket_count();

std::cout << "Load factors: " << load_7 << ", " << load_8 << ", " << load_9 << std::endl;
```

**Expected Ranges**:
- depth=7 (random expansion): 0.88-0.92 (good hash diversity)
- depth=8 (backtrace expansion): 0.65-0.90 (depends on sampling rate)
- depth=9 (backtrace expansion): 0.63-0.70 (lower due to filtering)

---

## 9. Migration Path

### 9.1 Phase 1: Data Collection (Week 1)

**Goal**: Populate `MEASURED_DATA` table

**Tasks**:
- [ ] Run empirical tests for all 7 models
- [ ] Record peak RSS for each model
- [ ] Measure load factors at depths 7, 8, 9
- [ ] Verify <2% variance across 10 runs
- [ ] Document environment (OS, CPU, compiler)

**Deliverable**: Completed `MEASURED_DATA` table with confidence intervals

### 9.2 Phase 2: Code Refactoring (Week 2)

**Goal**: Replace dynamic selection with table lookup

**Tasks**:
- [ ] Implement `BucketModel` enum
- [ ] Implement `BucketConfig` struct
- [ ] Replace `determine_bucket_sizes()` with `select_model_from_budget()`
- [ ] Update constructor to accept `BucketConfig`
- [ ] Add `MEASURED_DATA` lookup table
- [ ] Remove theoretical calculation code
- [ ] Remove 0.98 safety margin logic

**Deliverable**: Simplified codebase with measured-based selection

### 9.3 Phase 3: Research Modes (Week 3)

**Goal**: Enable developer exploration

**Tasks**:
- [ ] Implement `ResearchConfig` struct
- [ ] Add `enable_local_expansion` flag handling
- [ ] Add `ignore_memory_limits` flag handling
- [ ] Add CSV statistics output
- [ ] Add `dry_run` mode (no database save)
- [ ] Update constructor to accept `ResearchConfig`

**Deliverable**: Full BFS validation tools for new trainers

### 9.4 Phase 4: Memory Spike Elimination (Week 4)

**Goal**: Zero spikes in production code

**Tasks**:
- [ ] Pre-reserve all `index_pairs[d]` vectors
- [ ] Pre-reserve vectors used with `attach_element_vector()`
- [ ] Audit all vector operations for copy/realloc
- [ ] Run Valgrind/Heaptrack to detect spikes
- [ ] Fix identified spike sources
- [ ] Add regression test (spike <5% tolerance)

**Deliverable**: Production-ready code with predictable memory usage

### 9.5 Phase 5: Documentation & Testing (Week 5)

**Goal**: Complete system ready for production

**Tasks**:
- [ ] Update `SOLVER_IMPLEMENTATION.md` with new API
- [ ] Create migration guide for existing users
- [ ] Write unit tests for model selection
- [ ] Write integration tests for research modes
- [ ] Benchmark RSS across all models
- [ ] Update WASM build guide with new margin strategy

**Deliverable**: Documented, tested, production-ready system

---

## 10. Future Enhancements

### 10.1 Platform-Specific Tables

**Motivation**: Different platforms may have different RSS characteristics

**Implementation**:
```cpp
#ifdef __x86_64__
const auto& MEASURED_DATA = MEASURED_DATA_X64;
#elif defined(__aarch64__)
const auto& MEASURED_DATA = MEASURED_DATA_ARM64;
#elif defined(__wasm__)
const auto& MEASURED_DATA = MEASURED_DATA_WASM;
#endif
```

### 10.2 Adaptive Load Factor Tuning

**Motivation**: Automatically adjust bucket sizes if observed load factors drift

**Implementation**:
```cpp
// After expansion
double observed_load = depth_7_nodes.size() / (double)bucket_7;
double expected_load = MEASURED_DATA[model].avg_load_factor_7;

if (std::abs(observed_load - expected_load) > 0.05) {
    std::cerr << "[WARNING] Load factor drift detected: " 
              << observed_load << " vs " << expected_load << std::endl;
    // Recommend model update or bucket size adjustment
}
```

### 10.3 Persistent Measurement Database

**Motivation**: Accumulate measurements over time for statistical confidence

**Implementation**:
- Store measurements in JSON/SQLite
- Track min/max/mean/stddev across runs
- Detect anomalies (>3σ from mean)
- Automatically update `MEASURED_DATA` with new statistics

---

## 11. Summary

### Key Principles

1. **Measured Over Theoretical**: Real RSS data > calculated predictions
2. **Simple Over Complex**: Switch-case > optimization loops
3. **Explicit Over Implicit**: Named models > dynamic selection
4. **Research-Friendly**: Enable full BFS validation for new trainers
5. **Spike-Free**: Pre-allocate everything, avoid realloc/rehash
6. **Margin Transparency**: C++ uses minimal margin, caller adds environment-specific margin

### Benefits

- **Reliability**: No theoretical model failures (measured RSS is ground truth)
- **Simplicity**: Preset + custom models vs complex optimization loops
- **Flexibility**: Any power-of-2 bucket combination (343 possible configs)
- **Debuggability**: Clear validation, estimation, and selection logic
- **Research-Friendly**: Full BFS modes, custom buckets for exploration
- **Performance**: Zero allocation spikes (all vectors pre-reserved)
- **Extensibility**: **Easy to add depth 10, 11, 12** (just add bucket sizes)
- **Maintainability**: Update measurements when hardware/compiler changes

### Migration Checklist

- [ ] Collect empirical data (7 models × 10 runs)
- [ ] Implement `BucketModel`, `BucketConfig`, `ResearchConfig`
- [ ] Replace `determine_bucket_sizes()` with table lookup
- [ ] Add research mode handling
- [ ] Pre-reserve all vectors
- [ ] Remove safety margin logic (use measured peak)
- [ ] Test: model selection, research modes, memory spikes
- [ ] Document: API changes, migration guide, usage examples
- [ ] Deploy: update production code, WASM bindings

---

## 12. Easy Depth Expansion

### 12.1 Adding Depth 10 (and beyond)

**Motivation**: With the new flexible bucket system, adding depth 10 (or 11, 12, ...) is **trivial**.

**Steps**:

1. **Choose bucket size** (power of 2: 1M-64M):
   ```cpp
   size_t bucket_10 = 8 << 20;  // 8M for example
   ```

2. **Estimate capacity** from load factor:
   ```cpp
   size_t max_nodes_10 = bucket_10 * 0.63 * 1.05;  // Backtrace expansion
   ```

3. **Reserve vector**:
   ```cpp
   index_pairs[10].reserve(max_nodes_10);
   ```

4. **Run local expansion** (depth 9→10):
   ```cpp
   LocalExpansionResults results = local_bfs_n_to_n2(
       9,  // current_depth
       depth_9_nodes,
       // ... other params
   );
   ```

5. **Measure RSS**:
   ```cpp
   std::cout << "RSS after depth 10: " << (get_rss_kb() / 1024.0) << " MB" << std::endl;
   ```

6. **Update bucket config** with new (b7, b8, b9, b10) tuple.

**That's it!** No theoretical calculations, no complex logic. Just:
- Pick bucket size
- Reserve vector  
- Run expansion
- Measure RSS

### 12.2 Custom Configuration with Depth 10

```cpp
// Example: Extend to depth 10 with custom buckets
struct BucketConfigExtended {
    size_t bucket_7 = 4 << 20;   // 4M
    size_t bucket_8 = 8 << 20;   // 8M
    size_t bucket_9 = 8 << 20;   // 8M
    size_t bucket_10 = 16 << 20; // 16M (NEW)
};

// Estimate RSS
size_t estimated_rss = estimate_rss_from_buckets(cfg.bucket_7, cfg.bucket_8, 
                                                   cfg.bucket_9, cfg.bucket_10);

// Validate < 2GB for WASM
if (estimated_rss < 2048) {
    // Safe to proceed
}
```

### 12.3 Research Mode for Depth 10 Exploration

```cpp
// Test: Can we do depth 10 with 4GB RAM?
ResearchConfig research;
research.enable_local_expansion = true;   // Use local expansion
research.ignore_memory_limits = true;     // Ignore 2GB limit
research.collect_detailed_statistics = true;

BucketConfig cfg;
cfg.model = BucketModel::CUSTOM;
cfg.custom_bucket_7 = 8 << 20;
cfg.custom_bucket_8 = 16 << 20;
cfg.custom_bucket_9 = 16 << 20;
cfg.custom_bucket_10 = 32 << 20;  // Extended to depth 10

xxcross_search solver(true, 10, 4096, true, cfg, research);
// → Outputs RSS at each depth, validates feasibility
```

**Result**: CSV output shows exact RSS for depth 10 configuration, enabling data-driven decisions.

---

**Document Version**: 1.0  
**Implementation Status**: Design Specification (Not Yet Implemented)  
**Next Steps**: Phase 1 - Data Collection

**Related Documents**:
- [SOLVER_IMPLEMENTATION.md](SOLVER_IMPLEMENTATION.md) - Current implementation details
- [MEMORY_MONITORING.md](MEMORY_MONITORING.md) - RSS tracking techniques
- [WASM_BUILD_GUIDE.md](WASM_BUILD_GUIDE.md) - WebAssembly specifics
- [Experiences/MEMORY_THEORY_ANALYSIS.md](Experiences/MEMORY_THEORY_ANALYSIS.md) - Theoretical background
